{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20277370-1930-44f6-b7d8-72b0e69fbcd7",
   "metadata": {},
   "source": [
    "# **Taskifier - Intelligent Task Allocation & Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aa17b-2132-4662-9937-29788c19e82c",
   "metadata": {},
   "source": [
    "## Tech Stack\n",
    "* Langchain\n",
    "* LangGraph\n",
    "* Tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb898901-8df3-4521-8327-c9c3802c6c14",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa801f32-3c0a-4d57-a8b7-c07f61aacb60",
   "metadata": {},
   "source": [
    "Taskifier presents an agent that helps manage task management for productivity optimization. This tutorial utilizes Langchain and LangGraph to build a regulated pipeline for such purpose. It encompasses: \n",
    " - context breakdown & analysis\n",
    " - external resource retrieval (web search)\n",
    " - discretization of information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fa201-7245-43d8-978e-7b0f118be502",
   "metadata": {},
   "source": [
    "In the world of workforce, procrastination and messy workflow is a common phenomenon, particularly with college students or non-administration level personnel in workplace. This is often due to the lack of clarity in objectives with the tasks given to them. Suppose a SWE in a startup was given a task to build a sign-in page for a web app. Things get messy and discouraging when the SWE was trying to start coding and asked questions like, \"should I build an auth server first or should I create the front end first?\". Those questions can branch off to smaller sub-questions, leaving the task puzzling and therefore driving procrastination. This phenomenon is highly replicable across different industries as well.\n",
    "\n",
    "This projects aim at assisting in the analysis and organization of tasks that users need to complete. It utilizes the LLM's ability to qualitatively dissect information for such purpose. It will involve some behavioral analysis that adjusts the workstyle according to underlying patterns of how users approach different tasks, and thereby return an optimal workflow suggestion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa7202-8f59-4074-a302-5c5655b56f82",
   "metadata": {},
   "source": [
    "## Key Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48631a8e-f7e7-400a-9843-fd4d9c8439aa",
   "metadata": {},
   "source": [
    "1. Data Ingestion: Gathers data for approach analysis\n",
    "2. State Graph: Orchestrates steps from analysis to personalized generation\n",
    "3. Tavily Web Query: Searches for information on the task to maximize task proficiency\n",
    "4. LLM Model: Generates plans and analyzes approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec4b8e-1c8c-46f6-a467-335cb5229488",
   "metadata": {},
   "source": [
    "## Method Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1c4d8-4919-4f3b-bc74-4a8ab256942c",
   "metadata": {},
   "source": [
    "The system follows a step-by-step approach to personalize approaching plan for queried task:\n",
    "1. Approach Analysis: Breakdown how the user tends to carry out tasks (a step by step person? a plan-first-then-build approach?)\n",
    "2. Information Gathering: Retrieval of information related to the task in virtue of understanding what is necessary for completing the task\n",
    "3. Customized Approach Generation: Given the analyzed style, the LLM generates a customized approach according to the style. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4751e-3402-4d00-853e-e99c50e850de",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7349093-cdbf-4397-b046-e30e17562e06",
   "metadata": {},
   "source": [
    "This notebook exhibits the organized pipeline using LangGraph to induce step by step breakdown and generation of optimal response based on the user's preferences. It enables potential applications across different fields and different characters to optimize their workflow and productivity. Further analysis involving quantitative analysis can be used but given time limitation, we let LLM tackle the analysis of approach and yield the complete plan accordingly. Future improvements can involve behavioral analysis of decision making in quantitative terms, having multiple personas of different work attitudes and approach styles and match the user's preferences to the most similar personas, pivoting from user's feedbacks on generated response and tuning the style preference accordingly, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb57a08-7bc6-4118-b4ba-547208295074",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccde4d-60d8-4bd1-9e86-ec151337e77b",
   "metadata": {},
   "source": [
    "## Installation\n",
    "We will be using LangChain & LangGraph for building ensembles of agents & controlling their workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc585cf-8d2d-4ef5-9b18-eb16c8bfb6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install langchain langgraph tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0895fea-591e-4fcf-80f1-abe847e6cbb4",
   "metadata": {},
   "source": [
    "## Importations\n",
    "**Make sure you have the OpenAI and Tavily API Keys as part of your environment variables!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a0d85ff-84d7-44c7-beb8-74fd8708b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "from tavily import TavilyClient\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f6ca64-9fd6-40e3-a881-f69e93abec7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.personas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpersonas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Personas\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.personas'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89bce3f0-629c-4624-baa4-d7b98dc38004",
   "metadata": {},
   "source": [
    "## Base Agent Definition\n",
    "Key knowledge that agents should share:\n",
    " 1. each task comes with a deadlines\n",
    " 2. mandatory lookup of information for each task\n",
    " 3. they would have their own approach style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5dc361-d70e-457d-bf29-d7248e3bbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm, tools, system_message: str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful task management and organization AI assistant.\"\n",
    "                \" You will receive task that you will break down into steps based on your personalities, characters and work ethics.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\"\n",
    "                \" For each task, you will first look for information regarding the task using the tools provided and then give results based on your breakdown approach.\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9b764-e56d-475f-8634-ff750600b2ce",
   "metadata": {},
   "source": [
    "## State Definitions\n",
    "Here we define the states for the agent workflow. The states w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e925dcc-f9b7-4b4a-b0e3-6bc83923089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproachState(TypedDict):\n",
    "    plan: str  # detailed workflow of the approach\n",
    "    style: str # style description of the approach\n",
    "    task: str # user's input of task\n",
    "    details: str # internet retrieval of task specs\n",
    "    history: str # description of history approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e9cb3-e7ac-4d14-bb34-ceef3d2de17f",
   "metadata": {},
   "source": [
    "## LLM & Tavily Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba4f99a-6c34-453d-bb36-ecaeb54d6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a243be-c52d-4a58-a456-5e98f017168f",
   "metadata": {},
   "source": [
    "## Component Functions\n",
    "Define functions for...\n",
    "* Internet Query of Task Specs [retrieval]\n",
    "* Compare User Approach Preference vs Personas Approach Preference [filter approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1693c36d-1b2c-4b8e-8677-4c002bfc71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "def approach_analysis(approach: ApproachState) -> ApproachState:\n",
    "    \"\"\"Retrieve history approach and let LLM do a qualitative analysis on user approach preference.\"\"\"\n",
    "    history = \"\"\n",
    "    for h in os.listdir(f\"{os.getcwd()}/history\"):\n",
    "        if (h[-4:] == \".txt\"):\n",
    "            with open(os.path.join(os.getcwd(), f\"history/{h}\")) as f:\n",
    "                content = f.readlines()\n",
    "            history = f\"{history}\\n{content[0]}\"\n",
    "\n",
    "    approach['history'] = history\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the work style the following summary of work history portrays. \"\n",
    "        \"Provide a brief summary the preference in work style.\"\n",
    "        \"\\n\\nWork History: {history}\"\n",
    "    )\n",
    "    style = llm.invoke(prompt.format(history=approach['history']))\n",
    "    approach['style'] = style\n",
    "    return approach\n",
    "\n",
    "# def extract_aim(approach: ApproachState) -> ApproachState:\n",
    "#     \"\"\"Get key aims from the task query.\"\"\"\n",
    "\n",
    "def task_manifest(approach: ApproachState) -> ApproachState:\n",
    "    \"\"\"use Tavily to look up information on the task.\"\"\"\n",
    "\n",
    "    search_foundation = \"What are the steps for the following task? {task}\"\n",
    "    search_query = search_foundation.format(task=approach[\"task\"])\n",
    "    \n",
    "    searches = tavily_client.search(search_query, max_results=10)\n",
    "\n",
    "    details = \"\"\n",
    "\n",
    "    for result in searches['results']:\n",
    "        if details == \"\":\n",
    "            details = result['content']\n",
    "        else:\n",
    "            details = f\"{details} {result['content']}\"\n",
    "\n",
    "    approach[\"details\"] = details\n",
    "\n",
    "    return approach\n",
    "\n",
    "def result_approach(approach: ApproachState) -> ApproachState:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Give me a plan of steps to carry out the following task with custom work styles specified.\"\n",
    "        \"You have to pay extra attention to Work Style mentioned below and adjust the plan accordingly.\"\n",
    "        \"\\n\\nTask: {task}\\n\\nDetails: {details}\\n\\nWork Style: {style}\\n\\n\"\n",
    "        \"The output must be a numbered list of steps with explanation of why it is needed, what to do and how it considers the Work Style.\"\n",
    "    )\n",
    "\n",
    "    suggestion = llm.invoke(prompt.format(task=approach[\"task\"], details=approach[\"details\"], style=approach[\"style\"]))\n",
    "\n",
    "    approach['plan'] = suggestion\n",
    "\n",
    "    return approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36848c5-e278-40c0-b7b8-8e5eee8356a4",
   "metadata": {},
   "source": [
    "## Graph Workflow Building\n",
    "Now we can start to structure the workflow and organize them in order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5c63be8-c1d3-4278-a774-24900ca0a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(ApproachState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"approach_analysis\", approach_analysis)\n",
    "workflow.add_node(\"task_knowledge_retrieval\", task_manifest)\n",
    "workflow.add_node(\"customized_approach_generation\", result_approach)\n",
    "\n",
    "# Define and add conditional edges\n",
    "workflow.add_edge(\"approach_analysis\", \"task_knowledge_retrieval\")\n",
    "workflow.add_edge(\"task_knowledge_retrieval\", \"customized_approach_generation\")\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"approach_analysis\")\n",
    "\n",
    "# Set the exit point\n",
    "workflow.add_edge(\"customized_approach_generation\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26936bba-f637-4531-8156-752cfc0a5b79",
   "metadata": {},
   "source": [
    "## Agent Calling Function\n",
    "This function will be used to induce the entire workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc300ee0-32d5-45df-af62-125cb6e42d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach(task: str) -> ApproachState:\n",
    "    init_approach = ApproachState(\n",
    "        task=task,\n",
    "        plan=\"\",\n",
    "        style=\"\",\n",
    "        history=\"\",\n",
    "        details=\"\"\n",
    "    )\n",
    "\n",
    "    response = app.invoke(init_approach)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d76397-f392-4ae4-a97c-a32110d50fb2",
   "metadata": {},
   "source": [
    "### **🚀🚀🚀🚀🚀🚀🚀🚀 Great! Now we can start the inference and see how the workflow performs! 🚀🚀🚀🚀🚀🚀🚀🚀**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926fb09-79df-4b4c-ad42-52bb35973c01",
   "metadata": {},
   "source": [
    "## Example\n",
    "This is an example where the user hopes to build a smoke detector that is futuristic in design and accessible for installation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26182e39-29fa-43fa-81e5-652ced006154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:\n",
      "\n",
      "\n",
      "    I want to build a smoke detector device! I am visioning it with futuristic design and hope to maximize the ability to install it anywhere. Perhaps keep it small and energy efficient for that purpose!\n",
      "    \n",
      "\n",
      "Style:\n",
      "\n",
      "content=\"The work history summary portrays a systematic and pragmatic work style. The individual demonstrates a preference for tackling tasks in a structured manner, starting with simpler challenges to build confidence and familiarity before progressing to more complex issues. This approach reflects a methodical mindset and a desire to establish a strong foundation before confronting difficulties.\\n\\nIn the context of their venture into the medical IT field, the individual shows a proactive attitude by prioritizing regulatory challenges from the FDA and EMA, indicating a preference for addressing potential obstacles early on to avoid complications later. This indicates a forward-thinking approach and an inclination to mitigate risks.\\n\\nWhen it comes to job applications, the individual prefers to avoid extensive, time-consuming responses, suggesting a more straightforward, efficiency-driven work style. This preference for brevity indicates a focus on practicality and a desire to streamline processes, potentially valuing results over exhaustive detail.\\n\\nOverall, the individual's work style can be characterized as organized, proactive, and efficiency-oriented, with an emphasis on tackling tasks in a logical sequence and streamlining efforts to achieve goals.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 211, 'total_tokens': 416, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None} id='run-b1bdb405-a180-4354-bb70-fb68da28538e-0' usage_metadata={'input_tokens': 211, 'output_tokens': 205, 'total_tokens': 416, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Steps:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s a structured plan to build a futuristic, energy-efficient smoke detector device, tailored to your systematic and pragmatic work style:\n",
      "\n",
      "### Step 1: Define the Requirements\n",
      "**Why It’s Needed:** Establishing clear requirements helps in laying a strong foundation for the project. It ensures all stakeholders have a unified vision and expectations are aligned.\n",
      "\n",
      "**What to Do:** \n",
      "- Gather information on necessary features (e.g., smoke detection technology, IoT integration, energy efficiency).\n",
      "- Outline specifications such as size, power source, and design aesthetics.\n",
      "\n",
      "**How It Considers the Work Style:** This step addresses your preference for a structured approach by starting with a clear understanding of what needs to be achieved before diving into complex design and engineering tasks.\n",
      "\n",
      "### Step 2: Research and Select Components\n",
      "**Why It’s Needed:** Choosing the right components is crucial for performance, energy efficiency, and integration capabilities.\n",
      "\n",
      "**What to Do:**\n",
      "- Investigate various sensor technologies (e.g., photoelectric, ionization).\n",
      "- Evaluate energy-efficient microcontrollers and power sources (e.g., rechargeable batteries, solar).\n",
      "- Explore sustainable materials for the casing (e.g., bamboo, recycled plastics).\n",
      "\n",
      "**How It Considers the Work Style:** This step allows you to systematically review available options and make informed decisions, ensuring that you avoid potential complications later in the design process.\n",
      "\n",
      "### Step 3: Create a Prototype Design\n",
      "**Why It’s Needed:** A prototype helps visualize the final product and identify any design flaws or areas for improvement.\n",
      "\n",
      "**What to Do:**\n",
      "- Use CAD software to create a 3D model of the smoke detector.\n",
      "- Ensure the design is compact and aesthetically futuristic.\n",
      "- Plan for modularity to allow for future upgrades and integrations.\n",
      "\n",
      "**How It Considers the Work Style:** Designing a prototype focuses on practicality and efficiency, allowing for straightforward adjustments and refinements before the full-scale development begins.\n",
      "\n",
      "### Step 4: Develop Software for Smart Integration\n",
      "**Why It’s Needed:** Software is essential for the smart functionality of the device, enabling features like remote notifications and data monitoring.\n",
      "\n",
      "**What to Do:**\n",
      "- Develop a mobile app or integrate with existing smart home systems.\n",
      "- Implement real-time monitoring and data analytics for energy management.\n",
      "- Ensure compliance with relevant regulations (e.g., safety standards).\n",
      "\n",
      "**How It Considers the Work Style:** Addressing software development early on mitigates risks associated with regulatory compliance and ensures that the device can seamlessly integrate with other smart home technologies.\n",
      "\n",
      "### Step 5: Build and Test the Prototype\n",
      "**Why It’s Needed:** Testing is critical to verify that the device functions as intended and meets safety standards.\n",
      "\n",
      "**What to Do:**\n",
      "- Assemble the prototype using the selected components.\n",
      "- Conduct thorough testing for smoke detection efficacy and energy consumption.\n",
      "- Gather feedback from potential users for further refinement.\n",
      "\n",
      "**How It Considers the Work Style:** This step emphasizes an organized approach to problem-solving, allowing you to identify and address issues in a logical and systematic manner.\n",
      "\n",
      "### Step 6: Refine the Design Based on Testing Feedback\n",
      "**Why It’s Needed:** Refinement ensures the final product meets user needs and performs optimally.\n",
      "\n",
      "**What to Do:**\n",
      "- Analyze the testing data and user feedback to identify areas for improvement.\n",
      "- Make necessary adjustments to the design and functionality.\n",
      "- Re-test the updated prototype.\n",
      "\n",
      "**How It Considers the Work Style:** This iterative process aligns with your efficiency-driven mindset, focusing on continuous improvement and ensuring that the final product is both effective and market-ready.\n",
      "\n",
      "### Step 7: Plan for Production and Market Launch\n",
      "**Why It’s Needed:** A well-thought-out plan for production and marketing is essential for successful product launch and scalability.\n",
      "\n",
      "**What to Do:**\n",
      "- Identify manufacturing partners and production processes that adhere to sustainable practices.\n",
      "- Develop a marketing strategy highlighting the energy-efficient and smart features of the smoke detector.\n",
      "- Set a timeline for launch and distribution.\n",
      "\n",
      "**How It Considers the Work Style:** This structured approach to planning emphasizes practicality and efficiency, ensuring that all aspects of the product’s lifecycle are considered and managed in an organized manner.\n",
      "\n",
      "### Step 8: Monitor and Iterate Post-Launch\n",
      "**Why It’s Needed:** Continuous monitoring post-launch helps in identifying any performance issues and user feedback for future improvements.\n",
      "\n",
      "**What to Do:**\n",
      "- Collect data on device performance and customer satisfaction.\n",
      "- Address any issues promptly and plan for future iterations of the product based on user input.\n",
      "\n",
      "**How It Considers the Work Style:** This proactive approach to monitoring reflects your preference for mitigating risks early, ensuring long-term success and user satisfaction.\n",
      "\n",
      "By following this structured plan, you will effectively manage the complexity of building a smart smoke detector while adhering to your organized, pragmatic work style.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    I want to build a smoke detector device! I am visioning it with futuristic design and hope to maximize the ability to install it anywhere. Perhaps keep it small and energy efficient for that purpose!\n",
    "    \"\"\"\n",
    "\n",
    "## Some history is being fed into the Agent! It helps the agent understand users' approach preferences!\n",
    "generated_plan = approach(task=query)\n",
    "\n",
    "\n",
    "print(f\"Task:\\n\")\n",
    "print(f\"{generated_plan['task']}\\n\")\n",
    "print(f\"Style:\\n\")\n",
    "print(f\"{generated_plan['style']}\\n\")\n",
    "print(f\"Steps:\\n\")\n",
    "generated_plan['plan'].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
