{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Memory-Enhanced Email Agent with LangGraph\n",
    "\n",
    "This tutorial demonstrates how to build an advanced AI agent with three types of memory using LangGraph and LangMem. We'll create an email assistant that can remember important facts, learn from past examples, and improve its behavior based on feedback.\n",
    "\n",
    "## Key Memory Types:\n",
    "- **Semantic Memory**: Stores facts and knowledge about contacts, preferences, and contexts\n",
    "- **Episodic Memory**: Remembers specific past interactions and examples\n",
    "- **Procedural Memory**: Learns and improves behavioral patterns over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview: Email Assistant with Memory\n",
    "\n",
    "In this tutorial, we'll build an email agent that can:\n",
    "\n",
    "1. **Triage emails**: Classify incoming emails as 'ignore', 'notify', or 'respond'\n",
    "2. **Draft responses**: Compose contextually appropriate replies using stored knowledge\n",
    "3. **Learn from feedback**: Improve its performance based on user corrections\n",
    "\n",
    "The agent will leverage all three memory types to create a system that becomes more helpful and personalized over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting the Stage: Imports and Setup\n",
    "First, the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.store.memory import InMemoryStore  # For storing memories\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool # LangMem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\GenAI_Agents\\.venv\\Lib\\site-packages\\langgraph\\store\\base\\embed.py:95: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
      "  return init_embeddings(embed)\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables (your OpenAI API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "# Initialize the memory store (we'll use an in-memory store for simplicity)\n",
    "store = InMemoryStore(index={\"embed\": \"openai:text-embedding-3-small\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining Our Agent's \"Brain\": The State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    email_input: dict  # The incoming email\n",
    "    messages: Annotated[list, add_messages]  # The conversation history\n",
    "    triage_result: str # The result of the triage (ignore, notify, respond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Triage Center: Deciding What to Do (with Episodic Memory!)\n",
    "\n",
    "We'll enhance the triage step with episodic memory.\n",
    "\n",
    "First, let's define the Router:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(BaseModel):\n",
    "    reasoning: str = Field(description=\"Step-by-step reasoning behind the classification.\")\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore', 'notify', or 'respond'.\"\n",
    "    )\n",
    "\n",
    "llm_router = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the enhanced triage_email function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_few_shot_examples(examples):\n",
    "    formatted_examples = []\n",
    "    for eg in examples:\n",
    "        email = eg.value['email']\n",
    "        label = eg.value['label']\n",
    "        formatted_examples.append(\n",
    "            f\"From: {email['author']}\\nSubject: {email['subject']}\\nBody: {email['email_thread'][:300]}...\\n\\nClassification: {label}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(formatted_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_email(state: State, config: dict, store: InMemoryStore) -> dict:\n",
    "    email = state[\"email_input\"]\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "    namespace = (\"email_assistant\", user_id, \"examples\")  # Namespace for episodic memory\n",
    "\n",
    "    # Retrieve relevant examples from memory\n",
    "    examples = store.search(namespace, query=str(email))\n",
    "    formatted_examples = format_few_shot_examples(examples)\n",
    "\n",
    "    prompt_template = PromptTemplate.from_template(\"\"\"You are an email triage assistant.  Classify the following email:\n",
    "    From: {author}\n",
    "    To: {to}\n",
    "    Subject: {subject}\n",
    "    Body: {email_thread}\n",
    "\n",
    "    Classify as 'ignore', 'notify', or 'respond'.\n",
    "\n",
    "    Here are some examples of previous classifications:\n",
    "    {examples}\n",
    "    \"\"\")\n",
    "\n",
    "    prompt = prompt_template.format(examples=formatted_examples, **email)\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    result = llm_router.invoke(messages)\n",
    "    return {\"triage_result\": result.classification}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Action Time: Defining Tools (with Semantic Memory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    print(f\"Sending email to {to} with subject '{subject}'\\nContent:\\n{content}\\n\")\n",
    "    return f\"Email sent to {to} with subject '{subject}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangMem memory tools (using the configured user ID)\n",
    "manage_memory_tool = create_manage_memory_tool(namespace=(\"email_assistant\", \"{langgraph_user_id}\", \"collection\"))\n",
    "search_memory_tool = create_search_memory_tool(namespace=(\"email_assistant\", \"{langgraph_user_id}\", \"collection\"))\n",
    "\n",
    "tools = [write_email, check_calendar_availability, manage_memory_tool, search_memory_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The Response Agent: Putting It All Together (with Semantic Memory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def create_agent_prompt(state, config, store):\n",
    "    messages = state['messages']\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "    \n",
    "    # Get the current response prompt from procedural memory\n",
    "    system_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\").value\n",
    "    \n",
    "    return [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "\n",
    "# Try using the current API signature\n",
    "response_agent = create_react_agent(\n",
    "    tools=tools,\n",
    "    prompt=create_agent_prompt,\n",
    "    store=store,\n",
    "    model=llm  # Using 'model' instead of 'llm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Building the Graph: Connecting the Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "# Update this line to pass the store to the node\n",
    "workflow.add_node(\"triage\", lambda state, config: triage_email(state, config, store))\n",
    "workflow.add_node(\"response_agent\", response_agent)\n",
    "\n",
    "def route_based_on_triage(state):\n",
    "  if state[\"triage_result\"] == \"respond\":\n",
    "    return \"response_agent\"\n",
    "  else:\n",
    "    return END\n",
    "\n",
    "workflow.add_edge(START, \"triage\")\n",
    "workflow.add_conditional_edges(\"triage\", route_based_on_triage,\n",
    "                              {\n",
    "                                  \"response_agent\": \"response_agent\",\n",
    "                                  END: END\n",
    "                              })\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile(store=store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Let's Run It! (and Store Some Memories!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content=\"I'm here to help you with any questions you have about API documentation. If you're facing issues like missing endpoints or need clarification on specific sections, just let me know! I can provide you with guidance and useful resources. Feel free to share the details of your inquiry, and I'll get right on it!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 357, 'total_tokens': 419, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3267753c5d', 'id': 'chatcmpl-BCqgV2aStqNsYMAd6AzcfdzBGw42h', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b248411-9531-4e48-8fd9-37cf3d0c464c-0', usage_metadata={'input_tokens': 357, 'output_tokens': 62, 'total_tokens': 419, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "email_input = {\n",
    "    \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "    \"to\": \"John Doe <john.doe@company.com>\",\n",
    "    \"subject\": \"Quick question about API documentation\",\n",
    "    \"email_thread\": \"\"\"Hi John,\n",
    "\n",
    "I was reviewing the API documentation and noticed a few endpoints are missing. Could you help?\n",
    "\n",
    "Thanks,\n",
    "Alice\"\"\",\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"langgraph_user_id\": \"test_user\"}} # Set the user ID!\n",
    "inputs = {\"email_input\": email_input, \"messages\": []}\n",
    "\n",
    "for output in agent.stream(inputs, config=config): # Pass the config\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add few shot examples to memory\n",
    "example1 = {\n",
    "    \"email\": {\n",
    "        \"author\": \"Spammy Marketer <spam@example.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"BIG SALE!!!\",\n",
    "        \"email_thread\": \"Buy our product now and get 50% off!\",\n",
    "    },\n",
    "    \"label\": \"ignore\",\n",
    "}\n",
    "store.put((\"email_assistant\", \"test_user\", \"examples\"), \"spam_example\", example1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Adding Procedural Memory (Updating Instructions) - The Final Touch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedural memory allows the agent to learn and improve its instructions. This requires a separate agent (an \"optimizer\") to update the prompts based on feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_triage_prompt = \"\"\"You are an email triage assistant. Classify the following email:\n",
    "From: {author}\n",
    "To: {to}\n",
    "Subject: {subject}\n",
    "Body: {email_thread}\n",
    "\n",
    "Classify as 'ignore', 'notify', or 'respond'.\n",
    "\n",
    "Here are some examples of previous classifications:\n",
    "{examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response_prompt = \"\"\"You are a helpful assistant. Use the tools available, including memory tools, to assist the user.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store these prompts in the memory store\n",
    "store.put((\"email_assistant\", \"test_user\", \"prompts\"), \"triage_prompt\", initial_triage_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put((\"email_assistant\", \"test_user\", \"prompts\"), \"response_prompt\", initial_response_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_email_with_procedural_memory(state: State, config: dict, store: InMemoryStore) -> dict:\n",
    "    email = state[\"email_input\"]\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "    \n",
    "    # Retrieve the current triage prompt (procedural memory)\n",
    "    current_prompt_template = store.get((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\").value\n",
    "    \n",
    "    # Retrieve relevant examples from memory (episodic memory)\n",
    "    namespace = (\"email_assistant\", user_id, \"examples\")\n",
    "    examples = store.search(namespace, query=str(email))\n",
    "    formatted_examples = format_few_shot_examples(examples)\n",
    "    \n",
    "    # Format the prompt\n",
    "    prompt = PromptTemplate.from_template(current_prompt_template).format(examples=formatted_examples, **email)\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    result = llm_router.invoke(messages)\n",
    "    return {\"triage_result\": result.classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_multi_prompt_optimizer\n",
    "\n",
    "def optimize_prompts(feedback: str, config: dict, store: InMemoryStore):\n",
    "    \"\"\"Improve our prompts based on feedback.\"\"\"\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "    \n",
    "    # Get current prompts\n",
    "    triage_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\").value\n",
    "    response_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\").value\n",
    "    \n",
    "    # Create a more relevant test example based on our actual email\n",
    "    sample_email = {\n",
    "        \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"Quick question about API documentation\",\n",
    "        \"email_thread\": \"Hi John, I was reviewing the API documentation and noticed a few endpoints are missing. Could you help? Thanks, Alice\",\n",
    "    }\n",
    "    \n",
    "    # Create the optimizer\n",
    "    optimizer = create_multi_prompt_optimizer(llm)\n",
    "    \n",
    "    # Create a more relevant conversation trajectory with feedback\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": response_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"I received this email: {sample_email}\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"How can I assist you today?\"}\n",
    "    ]\n",
    "    \n",
    "    # Format prompts\n",
    "    prompts = [\n",
    "        {\"name\": \"triage\", \"prompt\": triage_prompt},\n",
    "        {\"name\": \"response\", \"prompt\": response_prompt}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # More relevant trajectories \n",
    "        trajectories = [(conversation, {\"feedback\": feedback})]\n",
    "        result = optimizer.invoke({\"trajectories\": trajectories, \"prompts\": prompts})\n",
    "        \n",
    "        # Extract the improved prompts\n",
    "        improved_triage_prompt = next(p[\"prompt\"] for p in result if p[\"name\"] == \"triage\")\n",
    "        improved_response_prompt = next(p[\"prompt\"] for p in result if p[\"name\"] == \"response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API error: {e}\")\n",
    "        print(\"Using manual prompt improvement as fallback\")\n",
    "        \n",
    "        # More specific manual improvements\n",
    "        improved_triage_prompt = triage_prompt + \"\\n\\nNote: Emails about API documentation or missing endpoints are high priority and should ALWAYS be classified as 'respond'.\"\n",
    "        improved_response_prompt = response_prompt + \"\\n\\nWhen responding to emails about documentation or API issues, acknowledge the specific issue mentioned and offer specific assistance rather than generic responses.\"\n",
    "    \n",
    "    # Store the improved prompts\n",
    "    store.put((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\", improved_triage_prompt)\n",
    "    store.put((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\", improved_response_prompt)\n",
    "    \n",
    "    print(f\"Triage prompt improved: {improved_triage_prompt[:100]}...\")\n",
    "    print(f\"Response prompt improved: {improved_response_prompt[:100]}...\")\n",
    "    \n",
    "    return \"Prompts improved based on feedback!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Let's Run Our Complete Memory-Enhanced Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_email_agent(store):\n",
    "    # Define the workflow\n",
    "    workflow = StateGraph(State)\n",
    "    workflow.add_node(\"triage\", lambda state, config: triage_email_with_procedural_memory(state, config, store))\n",
    "    \n",
    "    # Create a fresh response agent that will use the latest prompts\n",
    "    response_agent = create_react_agent(\n",
    "        tools=tools,\n",
    "        prompt=create_agent_prompt,\n",
    "        store=store,\n",
    "        model=llm\n",
    "    )\n",
    "    \n",
    "    workflow.add_node(\"response_agent\", response_agent)\n",
    "    \n",
    "    # The routing logic remains the same\n",
    "    workflow.add_edge(START, \"triage\")\n",
    "    workflow.add_conditional_edges(\"triage\", route_based_on_triage,\n",
    "                                {\n",
    "                                    \"response_agent\": \"response_agent\",\n",
    "                                    END: END\n",
    "                                })\n",
    "    \n",
    "    # Compile and return the graph\n",
    "    return workflow.compile(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing original email BEFORE optimization...\n",
      "\n",
      "\n",
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content=\"It seems like you're inquiring about API documentation. If you have specific questions or need certain information, please let me know! I can assist you with that or help you find particular resources related to API documentation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 325, 'total_tokens': 369, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'id': 'chatcmpl-BCr37jDPKBjQ05KmHFrE52jreoTqu', 'finish_reason': 'stop', 'logprobs': None}, id='run-9447505b-3103-4ac8-b92e-7cb2107a3bc6-0', usage_metadata={'input_tokens': 325, 'output_tokens': 44, 'total_tokens': 369, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n",
      "Added API documentation example to episodic memory\n",
      "Triage prompt improved: You are an email triage assistant. Classify the following email: \n",
      "From: {author} \n",
      "To: {to} \n",
      "Subject:...\n",
      "Response prompt improved: You are a helpful assistant. Prioritize inquiries about critical topics like API documentation by ac...\n",
      "\n",
      "\n",
      "Processing the SAME email AFTER optimization with a fresh agent...\n",
      "\n",
      "\n",
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content=\"It sounds like you're inquiring about API documentation, and I noticed you mentioned a specific issue regarding missing endpoints. Can you please provide more details about which endpoints you're looking for or the specific API you're referring to? This will help me guide you more effectively in resolving the issue.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 349, 'total_tokens': 406, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'id': 'chatcmpl-BCr3baeSXDdZ2KsTPgaDdQxGrFO5Z', 'finish_reason': 'stop', 'logprobs': None}, id='run-959b390f-4af5-4a9f-b288-003cd7b8316c-0', usage_metadata={'input_tokens': 349, 'output_tokens': 57, 'total_tokens': 406, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# First process the original email to capture \"before\" behavior\n",
    "print(\"\\n\\nProcessing original email BEFORE optimization...\\n\\n\")\n",
    "agent = create_email_agent(store)  # Create a fresh agent\n",
    "for output in agent.stream(inputs, config=config):\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")\n",
    "\n",
    "# Add a specific example to episodic memory\n",
    "api_doc_example = {\n",
    "    \"email\": {\n",
    "        \"author\": \"Developer <dev@company.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"API Documentation Issue\", \n",
    "        \"email_thread\": \"Found missing endpoints in the API docs. Need urgent update.\",\n",
    "    },\n",
    "    \"label\": \"respond\",\n",
    "}\n",
    "store.put((\"email_assistant\", \"test_user\", \"examples\"), \"api_doc_example\", api_doc_example)\n",
    "print(\"Added API documentation example to episodic memory\")\n",
    "\n",
    "# Provide feedback\n",
    "feedback = \"\"\"The agent didn't properly recognize that emails about API documentation issues \n",
    "are high priority and require immediate attention. When an email mentions \n",
    "'API documentation', it should always be classified as 'respond' with a helpful tone.\n",
    "Also, instead of just responding with 'How can I assist you today?', the agent should \n",
    "acknowledge the specific documentation issue mentioned and offer assistance.\"\"\"\n",
    "\n",
    "# Optimize prompts\n",
    "optimize_prompts(feedback, config, store)\n",
    "\n",
    "# Process the SAME email after optimization with a FRESH agent\n",
    "print(\"\\n\\nProcessing the SAME email AFTER optimization with a fresh agent...\\n\\n\")\n",
    "new_agent = create_email_agent(store)  # Create a fresh agent with updated prompts\n",
    "for output in new_agent.stream(inputs, config=config):\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: From Simple Scripts to Truly Intelligent Assistants\n",
    "\n",
    "We've now built an email agent that's far more than a simple script. Like a skilled human assistant who grows more valuable over time, our agent builds a multi-faceted memory system:\n",
    "\n",
    "1. **Semantic Memory**: A knowledge base of facts about your work context, contacts, and preferences\n",
    "2. **Episodic Memory**: A collection of specific examples that guide decision-making through pattern recognition\n",
    "3. **Procedural Memory**: The ability to improve its own processes based on feedback and experience\n",
    "\n",
    "This agent demonstrates how combining different types of memory creates an assistant that actually learns from interactions and gets better over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
